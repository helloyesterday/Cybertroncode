{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2024 @ Shenzhen Bay Laboratory & Peking University & Huawei Technologies Co., Ltd\n",
    "\n",
    "This code is a part of MindSPONGE:\n",
    "MindSpore Simulation Package tOwards Next Generation molecular modelling.\n",
    "\n",
    "MindSPONGE is open-source software based on the AI-framework:\n",
    "MindSpore (https://www.mindspore.cn/)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training forcefield model with Cybertron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置环境, 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['MINDSPONGE_HOME']='/home/mindspore/work/summerschool/mindscience/MindSPONGE/src'\n",
    "os.environ['GLOG_v']=str(4)\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import dataset as ds\n",
    "from mindspore import context\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cybertron import Cybertron\n",
    "from cybertron.model import MolCT\n",
    "from cybertron.embedding import MolEmbedding\n",
    "from cybertron.readout import AtomwiseReadout\n",
    "from cybertron.train import MolWithLossCell, MolWithEvalCell\n",
    "from cybertron.train.lr import TransformerLR\n",
    "from cybertron.train.loss import MSELoss\n",
    "from cybertron.train.metric import MAE, RMSE, Loss\n",
    "from cybertron.train.callback import TrainMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = data_dir + '/dataset/data_normed_'\n",
    "\n",
    "train_file = sys_name + 'trainset_83197_64_64.npz'\n",
    "valid_file = sys_name + 'validset_128.npz'\n",
    "\n",
    "train_data = np.load(train_file)\n",
    "valid_data = np.load(valid_file)\n",
    "\n",
    "atom_type = Tensor(train_data['atom_type'], ms.int32)\n",
    "scale = train_data['scale']\n",
    "shift = train_data['shift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置训练网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_feature = 128\n",
    "activation = 'silu'\n",
    "\n",
    "emb = MolEmbedding(\n",
    "    dim_node=dim_feature,\n",
    "    emb_dis=True,\n",
    "    emb_bond=False,\n",
    "    cutoff=1,\n",
    "    cutoff_fn='smooth',\n",
    "    rbf_fn='log_gaussian',\n",
    "    activation=activation,\n",
    "    length_unit='nm',\n",
    ")\n",
    "\n",
    "mod = MolCT(\n",
    "    dim_feature=dim_feature,\n",
    "    dim_edge_emb=emb.dim_edge,\n",
    "    n_interaction=3,\n",
    "    n_heads=8,\n",
    "    activation=activation,\n",
    ")\n",
    "\n",
    "readout = AtomwiseReadout(\n",
    "    dim_output=1,\n",
    "    dim_node_rep=dim_feature,\n",
    "    activation=activation,\n",
    ")\n",
    "\n",
    "net = Cybertron(embedding=emb, model=mod, readout=readout, atom_type=atom_type, length_unit='nm')\n",
    "_ = net.set_scaleshift(scale=scale, shift=shift)\n",
    "\n",
    "conf_dir = data_dir + '/conf'\n",
    "_ = net.save_configure('configure_MolCT' + '.yaml' , conf_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印网络参数情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 embedding.atom_embedding.embedding_table (64, 128)\n",
      "1 model.filter_net.linear.weight (128, 64)\n",
      "2 model.filter_net.linear.bias (128,)\n",
      "3 model.filter_net.residual.nonlinear.mlp.0.weight (128, 128)\n",
      "4 model.filter_net.residual.nonlinear.mlp.0.bias (128,)\n",
      "5 model.filter_net.residual.nonlinear.mlp.1.weight (128, 128)\n",
      "6 model.filter_net.residual.nonlinear.mlp.1.bias (128,)\n",
      "7 model.interaction.0.positional_embedding.norm.gamma (128,)\n",
      "8 model.interaction.0.positional_embedding.norm.beta (128,)\n",
      "9 model.interaction.0.positional_embedding.x2q.weight (128, 128)\n",
      "10 model.interaction.0.positional_embedding.x2k.weight (128, 128)\n",
      "11 model.interaction.0.positional_embedding.x2v.weight (128, 128)\n",
      "12 model.interaction.0.multi_head_attention.output.weight (128, 128)\n",
      "13 model.interaction.1.positional_embedding.norm.gamma (128,)\n",
      "14 model.interaction.1.positional_embedding.norm.beta (128,)\n",
      "15 model.interaction.1.positional_embedding.x2q.weight (128, 128)\n",
      "16 model.interaction.1.positional_embedding.x2k.weight (128, 128)\n",
      "17 model.interaction.1.positional_embedding.x2v.weight (128, 128)\n",
      "18 model.interaction.1.multi_head_attention.output.weight (128, 128)\n",
      "19 model.interaction.2.positional_embedding.norm.gamma (128,)\n",
      "20 model.interaction.2.positional_embedding.norm.beta (128,)\n",
      "21 model.interaction.2.positional_embedding.x2q.weight (128, 128)\n",
      "22 model.interaction.2.positional_embedding.x2k.weight (128, 128)\n",
      "23 model.interaction.2.positional_embedding.x2v.weight (128, 128)\n",
      "24 model.interaction.2.multi_head_attention.output.weight (128, 128)\n",
      "25 readout.0.decoder.output.mlp.0.weight (64, 128)\n",
      "26 readout.0.decoder.output.mlp.0.bias (64,)\n",
      "27 readout.0.decoder.output.mlp.1.weight (1, 64)\n",
      "28 readout.0.decoder.output.mlp.1.bias (1,)\n",
      "Total parameters:  255233\n",
      "================================================================================\n",
      "Cybertron Engine, Ride-on!\n",
      "--------------------------------------------------------------------------------\n",
      "    Using fixed atom type index:\n",
      "       Atom 0      : 8\n",
      "       Atom 1      : 6\n",
      "       Atom 2      : 6\n",
      "       Atom 3      : 6\n",
      "       Atom 4      : 6\n",
      "       Atom 5      : 6\n",
      "       Atom 6      : 6\n",
      "       Atom 7      : 1\n",
      "       Atom 8      : 1\n",
      "       Atom 9      : 1\n",
      "       Atom 10     : 1\n",
      "       Atom 11     : 1\n",
      "       Atom 12     : 1\n",
      "       Atom 13     : 1\n",
      "       Atom 14     : 1\n",
      "--------------------------------------------------------------------------------\n",
      "    Graph Embedding: MolEmbedding\n",
      "--------------------------------------------------------------------------------\n",
      "       Length unit: nm\n",
      "       Atom embedding size: 64\n",
      "       Cutoff distance: 1.0 nm\n",
      "       Cutoff function: SmoothCutoff\n",
      "       Radical basis functions: LogGaussianBasis\n",
      "          Minimum distance: 0.04 nm\n",
      "          Maximum distance: 1.0 nm\n",
      "          Reference distance: 1.0 nm\n",
      "          Log Gaussian begin: -3.218876\n",
      "          Log Gaussian end: 0.006724119\n",
      "          Interval for log Gaussian: 0.0512\n",
      "          Sigma for log gaussian: 0.3\n",
      "          Number of basis functions: 64\n",
      "          Rescale the range of RBF to (-1, 1).\n",
      "       Embedding distance: True\n",
      "       Embedding Bond: False\n",
      "       Dimension of node embedding vector: 128\n",
      "       Dimension of edge embedding vector: 64\n",
      "--------------------------------------------------------------------------------\n",
      "    Deep molecular model: MolCT\n",
      "--------------------------------------------------------------------------------\n",
      "       Dimension of node representation vector: 128\n",
      "       Dimension of edge representation vector: 128\n",
      "       Dimension of node embedding vector: 128\n",
      "       Dimension of edge embedding vector: 64\n",
      "       Using 3 independent interaction layers:\n",
      "       0. NeuralInteractionUnit\n",
      "          Feature dimension: 128\n",
      "          Activation function: SiLU\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "       1. NeuralInteractionUnit\n",
      "          Feature dimension: 128\n",
      "          Activation function: SiLU\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "       2. NeuralInteractionUnit\n",
      "          Feature dimension: 128\n",
      "          Activation function: SiLU\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "--------------------------------------------------------------------------------\n",
      "    With 1 readout networks: \n",
      "--------------------------------------------------------------------------------\n",
      "    0. AtomwiseReadout\n",
      "       Activation function: SiLU<>\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "       Scale: [4.6406326]\n",
      "       Shift: [-538.7574]\n",
      "       Reference value for atom types: 0.0\n",
      "       Scale the shift by the number of atoms: True\n",
      "--------------------------------------------------------------------------------\n",
      "    Input unit: nm\n",
      "    Output unit: None\n",
      "    Input unit scale: 1.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "tot_params = 0\n",
    "for i, param in enumerate(net.trainable_params()):\n",
    "    tot_params += param.size\n",
    "    print(i, param.name, param.shape)\n",
    "print('Total parameters: ', tot_params)\n",
    "\n",
    "net.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据集分batch, 包装训练网络和loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell wrapper: MolWithLossCell\n",
      "    Input arguments:\n",
      "       Argument 0: coordinate\n",
      "    Labels, loss function and weights:\n",
      "       Label 0: energy,  loss: MSELoss,  weight: 0.00990099.\n",
      "       Label 1: force,  loss: MSELoss,  weight: 0.990099.\n",
      "    Calculate force using automatic differentiation: True\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 10\n",
    "REPEAT_TIME = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ds_train = ds.NumpySlicesDataset(\n",
    "    {'coordinate': train_data['coordinate'],\n",
    "        'energy': train_data['label'],\n",
    "        'force': train_data['force'],\n",
    "        }, shuffle=True)\n",
    "\n",
    "data_keys = ds_train.column_names\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.repeat(REPEAT_TIME)\n",
    "\n",
    "force_dis = train_data['avg_force_dis']\n",
    "loss_network = MolWithLossCell(data_keys=data_keys,\n",
    "                                network=net,\n",
    "                                loss_fn=[MSELoss(), MSELoss(force_dis=force_dis)],\n",
    "                                calc_force=True,\n",
    "                                loss_weights=[1, 100],\n",
    "                                )\n",
    "loss_network.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证数据集分batch, 包装训练网络和evaluation loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell wrapper: MolWithEvalCell\n",
      "    Input arguments:\n",
      "       Argument 0: coordinate\n",
      "    Labels, loss function and weights:\n",
      "       Label 0: energy,  loss: MSELoss,  weight: 0.00990099.\n",
      "       Label 1: force,  loss: MSELoss,  weight: 0.990099.\n",
      "    Calculate force using automatic differentiation: True\n",
      "    Using normalized dataset: True\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ds_valid = ds.NumpySlicesDataset(\n",
    "    {'coordinate': valid_data['coordinate'],\n",
    "        'energy': valid_data['label'],\n",
    "        'force': valid_data['force'],\n",
    "        }, shuffle=True)\n",
    "data_keys = ds_valid.column_names\n",
    "ds_valid = ds_valid.batch(128)\n",
    "ds_valid = ds_valid.repeat(1)\n",
    "\n",
    "eval_network = MolWithEvalCell(data_keys=data_keys,\n",
    "                                network=net,\n",
    "                                loss_fn=[MSELoss(), MSELoss(force_dis=force_dis)],\n",
    "                                calc_force=True,\n",
    "                                loss_weights=[1, 100],\n",
    "                                normed_evaldata=True\n",
    "                                )\n",
    "eval_network.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置学习率和优化器, 包装训练模型, 设置输出模型情况,和checkpoint文件的保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = TransformerLR(learning_rate=1., warmup_steps=4000, dimension=dim_feature)\n",
    "optim = nn.Adam(params=net.trainable_params(), learning_rate=lr)\n",
    "energy_mae = 'EnergyMAE'\n",
    "forces_mae = 'ForcesMAE'\n",
    "forces_rmse = 'ForcesRMSE'\n",
    "eval_loss = 'EvalLoss'\n",
    "model = Model(loss_network, eval_network=eval_network, optimizer=optim,\n",
    "                metrics={eval_loss: Loss(), energy_mae: MAE(0), forces_mae: MAE(1),\n",
    "                        forces_rmse: RMSE(1)})\n",
    "\n",
    "ckpt_name = 'cybertron-' + net.model_name.lower()\n",
    "ckpt_dir = data_dir + '/ckpt'\n",
    "record_cb = TrainMonitor(model, ckpt_name, per_epoch=1, avg_steps=32,\n",
    "                            directory=ckpt_dir, eval_dataset=ds_valid, best_ckpt_metrics=forces_rmse)\n",
    "\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=32, keep_checkpoint_max=64)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=ckpt_name, directory=ckpt_dir, config=config_ck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(3878979:140103317907264,MainProcess):2024-08-19-15:32:59.629.597 [mindspore/train/model.py:1118] For TrainMonitor callback, {'epoch_end', 'begin', 'step_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch: 1, Step: 128, Learning_rate: 4.4371976e-05, Last_Loss: 0.74542654, Avg_loss: 0.9044692646712065, EvalLoss: 0.6588590741157532, EnergyMAE: 48.16619110107422, ForcesMAE: 694.361328125, ForcesRMSE: 1757.4310797297287\n",
      "Epoch: 2, Step: 256, Learning_rate: 8.909333e-05, Last_Loss: 0.18310946, Avg_loss: 0.20136635564267635, EvalLoss: 0.18085232377052307, EnergyMAE: 42.73646926879883, ForcesMAE: 372.437109375, ForcesRMSE: 912.9966045939054\n",
      "Epoch: 3, Step: 384, Learning_rate: 0.0001338147, Last_Loss: 0.14448962, Avg_loss: 0.11873087473213673, EvalLoss: 0.11840511858463287, EnergyMAE: 15.34036636352539, ForcesMAE: 308.76402994791664, ForcesRMSE: 746.9594812750332\n",
      "Epoch: 4, Step: 512, Learning_rate: 0.00017853607, Last_Loss: 0.082165144, Avg_loss: 0.09984835772775114, EvalLoss: 0.10890037566423416, EnergyMAE: 76.10836791992188, ForcesMAE: 284.77265625, ForcesRMSE: 676.0275142329638\n",
      "Epoch: 5, Step: 640, Learning_rate: 0.0002232574, Last_Loss: 0.08014881, Avg_loss: 0.08233692357316613, EvalLoss: 0.0764656662940979, EnergyMAE: 15.434783935546875, ForcesMAE: 253.620458984375, ForcesRMSE: 599.1911492448243\n",
      "Epoch: 6, Step: 768, Learning_rate: 0.0002679788, Last_Loss: 0.06408447, Avg_loss: 0.06623053445946425, EvalLoss: 0.0687038004398346, EnergyMAE: 19.00255584716797, ForcesMAE: 240.08896484375, ForcesRMSE: 566.0727868392898\n",
      "Epoch: 7, Step: 896, Learning_rate: 0.00031270014, Last_Loss: 0.07727416, Avg_loss: 0.06364978395868093, EvalLoss: 0.07121634483337402, EnergyMAE: 46.32789993286133, ForcesMAE: 237.57067057291667, ForcesRMSE: 561.0518692598752\n",
      "Epoch: 8, Step: 1024, Learning_rate: 0.0003574215, Last_Loss: 0.06271984, Avg_loss: 0.06287520611658692, EvalLoss: 0.056450605392456055, EnergyMAE: 20.756847381591797, ForcesMAE: 216.65286458333333, ForcesRMSE: 511.9642240104934\n",
      "Epoch: 9, Step: 1152, Learning_rate: 0.00040214288, Last_Loss: 0.07038381, Avg_loss: 0.05789398273918778, EvalLoss: 0.07090207934379578, EnergyMAE: 79.70144653320312, ForcesMAE: 219.97345377604168, ForcesRMSE: 521.1937739459289\n",
      "Epoch: 10, Step: 1280, Learning_rate: 0.00044686423, Last_Loss: 0.050615273, Avg_loss: 0.05023755400907248, EvalLoss: 0.051059290766716, EnergyMAE: 32.524696350097656, ForcesMAE: 204.48855794270833, ForcesRMSE: 478.7734328468947\n",
      "Training Fininshed!\n",
      "Training Time: 00:00:52\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training ...\")\n",
    "beg_time = time.time()\n",
    "model.train(N_EPOCH, ds_train, callbacks=[\n",
    "            record_cb, ckpoint_cb], dataset_sink_mode=False)\n",
    "end_time = time.time()\n",
    "used_time = end_time - beg_time\n",
    "m, s = divmod(used_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Training Fininshed!\")\n",
    "print(\"Training Time: %02d:%02d:%02d\" % (h, m, s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms22_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
